{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import regex as re\n",
    "import zipfile\n",
    "import gc\n",
    "from scipy.stats import boxcox\n",
    "import sys \n",
    "# other python utilities \n",
    "from collections import Counter \n",
    "from tqdm import tqdm \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import warnings, math\n",
    "from termcolor import colored\n",
    "import pickle\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# for eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "\n",
    "# for SVD\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.sparse import csr_matrix\n",
    "pd.set_option('display.float_format','{:.2f}'.format)\n",
    "\n",
    "# for TFIDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy\n",
    "from sklearn import preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Grade Level Category\n",
      "Project Resource Category\n",
      "Project Current Status\n",
      "School Metro Type\n",
      "School State\n",
      "Donor State\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:\\Papers\\Paper 3 - Recommender Systems\\Recommender-systems\\Files\\Oct_Forth_projectType.csv\")\n",
    "\n",
    "categories_cols = []\n",
    "\n",
    "for col in df.columns:\n",
    "    #print(str(col))\n",
    "    cats = len(df[col].unique())\n",
    "    #print(cats)\n",
    "    if cats<=10:\n",
    "        categories_cols.append(col)\n",
    "        print(col)\n",
    "        \n",
    "df[categories_cols] = df[categories_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project ID</th>\n",
       "      <th>Donation ID</th>\n",
       "      <th>Donor ID</th>\n",
       "      <th>Donation Amount</th>\n",
       "      <th>Donation Received Date</th>\n",
       "      <th>School ID</th>\n",
       "      <th>Project Title</th>\n",
       "      <th>Project Need Statement</th>\n",
       "      <th>Project Subject Category Tree</th>\n",
       "      <th>Project Subject Subcategory Tree</th>\n",
       "      <th>...</th>\n",
       "      <th>Project Cost</th>\n",
       "      <th>Project Posted Date</th>\n",
       "      <th>Project Expiration Date</th>\n",
       "      <th>Project Current Status</th>\n",
       "      <th>Project Fully Funded Date</th>\n",
       "      <th>School Metro Type</th>\n",
       "      <th>School State</th>\n",
       "      <th>School Zip</th>\n",
       "      <th>Donor State</th>\n",
       "      <th>Donor Zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0029e426fd3296af4fc333580fa895fe</td>\n",
       "      <td>061a5652846763d2eca84535978a647b</td>\n",
       "      <td>0e345dcdef0d2a36c9bd17bf1ac3e10a</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2014-08-10 20:32:12</td>\n",
       "      <td>55fe7ff4c71893998d0e9a26a9d3d0b7</td>\n",
       "      <td>Everyone Needs an Address, Especially Maniac M...</td>\n",
       "      <td>My students need a class set of the book Mania...</td>\n",
       "      <td>Applied Learning, Literacy &amp; Language</td>\n",
       "      <td>Character Education, Literature &amp; Writing</td>\n",
       "      <td>...</td>\n",
       "      <td>510.00</td>\n",
       "      <td>2014-06-12</td>\n",
       "      <td>2014-10-09</td>\n",
       "      <td>Fully Funded</td>\n",
       "      <td>2014-08-23</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>30238</td>\n",
       "      <td>California</td>\n",
       "      <td>900.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Project ID                       Donation ID  \\\n",
       "0  0029e426fd3296af4fc333580fa895fe  061a5652846763d2eca84535978a647b   \n",
       "\n",
       "                           Donor ID  Donation Amount Donation Received Date  \\\n",
       "0  0e345dcdef0d2a36c9bd17bf1ac3e10a             0.68    2014-08-10 20:32:12   \n",
       "\n",
       "                          School ID  \\\n",
       "0  55fe7ff4c71893998d0e9a26a9d3d0b7   \n",
       "\n",
       "                                       Project Title  \\\n",
       "0  Everyone Needs an Address, Especially Maniac M...   \n",
       "\n",
       "                              Project Need Statement  \\\n",
       "0  My students need a class set of the book Mania...   \n",
       "\n",
       "           Project Subject Category Tree  \\\n",
       "0  Applied Learning, Literacy & Language   \n",
       "\n",
       "            Project Subject Subcategory Tree  ... Project Cost  \\\n",
       "0  Character Education, Literature & Writing  ...       510.00   \n",
       "\n",
       "  Project Posted Date  Project Expiration Date Project Current Status  \\\n",
       "0          2014-06-12               2014-10-09           Fully Funded   \n",
       "\n",
       "  Project Fully Funded Date School Metro Type School State School Zip  \\\n",
       "0                2014-08-23          suburban      Georgia      30238   \n",
       "\n",
       "  Donor State  Donor Zip  \n",
       "0  California     900.00  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22919\n",
      "48546\n"
     ]
    }
   ],
   "source": [
    "# only for checking\n",
    "donor_project = df.groupby(['Donor ID', 'Project ID'])['Donation Amount'].sum().reset_index()\n",
    "print(f\"{len(donor_project)}\")\n",
    "print(f\"{len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# create a df for \n",
    "\n",
    "donors_projects_df = donor_project.pivot('Donor ID', 'Project ID', 'Donation Amount').fillna(0)\n",
    "\n",
    "donors_projects = donors_projects_df.values\n",
    "donors_id = donors_projects_df.index\n",
    "projects_id = donors_projects_df.columns\n",
    "\n",
    "print(f'length of donors: {len(donors_id)}')\n",
    "print(f'length of projects: {len(projects_id)}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scipy) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scipy --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 860/860 [00:00<00:00, 6674.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(projects_id) =  860\n",
      "len(project_txt) =  860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create a df for projects specifications\n",
    "projects_df = df[['Project ID', 'Project Subject Subcategory Tree', 'Project Title', 'Project Need Statement', 'School State']].drop_duplicates(['Project ID']).reset_index(drop=True)\n",
    "projects_id = projects_df['Project ID'].tolist()\n",
    "print(\"len(projects_id) = \", len(projects_id) )\n",
    "# clean the text\n",
    "patterns = ['Â', '']\n",
    "punct = re.sub(r'[\\&\\.\\,]', '', string.punctuation)\n",
    "\n",
    "def clean(text):\n",
    "    for pattern in patterns:\n",
    "        text = re.sub(pattern, ' ', text)\n",
    "    text = text.translate(str.maketrans('', '', punct))\n",
    "    text = text.lower()\n",
    "    text = re.sub(r' +(?![iaIA])[\\w] +', ' ', text)\n",
    "    text = re.sub(r' \\s+', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# add them up\n",
    "project_txt = []\n",
    "\n",
    "for i in tqdm(range(len(projects_df)), position=0, leave=True):\n",
    "    project_txt.append(\n",
    "        clean(projects_df.loc[i, 'Project Title'] + ' & ' + projects_df.loc[i, 'Project Need Statement'] + ' & ' + projects_df.loc[i, 'Project Subject Subcategory Tree'] + ' & ' + projects_df.loc[i, 'School State'])\n",
    "        )\n",
    "\n",
    "projects_df.loc[:, 'Project TFIDF Text'] = project_txt\n",
    "print(\"len(project_txt) = \", len(project_txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_matrix.shape = (860, 3074)\n"
     ]
    }
   ],
   "source": [
    "# TFIDF\n",
    "vectorizer = TfidfVectorizer(max_df = 0.99,    \n",
    "                             min_df = 0.001,\n",
    "                             stop_words='english',\n",
    "                             strip_accents='unicode',\n",
    "                             analyzer='word')\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(project_txt)\n",
    "\n",
    "print(f\"tfidf_matrix.shape = {tfidf_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# donations in Train set:  43,691\n",
      "# donations in Test set:  4,855\n",
      "# Donors in Train set:  795\n",
      "# Donors in Test set:  618\n",
      "# Donors in both Train and Test sets - the ones we choose for evaluation:  \u001b[34m618\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "print('# donations in Train set: ', f\"{len(df_train):,}\")\n",
    "print('# donations in Test set: ',  f\"{len(df_test):,}\")\n",
    "\n",
    "print('# Donors in Train set: ', f\"{len(df_train['Donor ID'].unique()):,}\")\n",
    "print('# Donors in Test set: ',  f\"{len(df_test['Donor ID'].unique()):,}\")\n",
    "\n",
    "\n",
    "print('# Donors in both Train and Test sets - the ones we choose for evaluation: ',\n",
    "      colored(f\"{len(df_train[df_train['Donor ID'].isin(df_test['Donor ID'].values.tolist())]['Donor ID'].unique()):,}\", 'blue'))\n",
    "\n",
    "\n",
    "\n",
    "df_train = df_train[df_train['Donor ID'].isin(df_test['Donor ID'].values.tolist())].reset_index(drop=True)\n",
    "df_test = df_test[df_test['Donor ID'].isin(df_train['Donor ID'].values.tolist())].reset_index(drop=True)\n",
    "\n",
    "# sum of donation in a grouped by donor id dataset\n",
    "df_donor_index = df.groupby(by = ['Donor ID', 'Project ID']).sum()[['Donation Amount']].reset_index().set_index('Donor ID')\n",
    "df_train_donor_index = df_train.groupby(by = ['Donor ID', 'Project ID']).sum()[['Donation Amount']].reset_index().set_index('Donor ID')\n",
    "df_test_donor_index = df_test.groupby(by = ['Donor ID', 'Project ID']).sum()[['Donation Amount']].reset_index().set_index('Donor ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Donor ID</th>\n",
       "      <th>donated_projects_test</th>\n",
       "      <th>donated_projects_train</th>\n",
       "      <th>Donation ID_test</th>\n",
       "      <th>Donation ID_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7f7fca83ead83a4bb01123429d3114ef</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>787a3bb8aaf99727563c1f62f98610c5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>774836dd111e337194f91e517df9eb94</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76d0cdb881c521e1743118634f0c5f28</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f0ea78ff6ce64e89e929948a60ea09d9</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>c376c98b0cdb746cf025bb21ee810376</td>\n",
       "      <td>49</td>\n",
       "      <td>239</td>\n",
       "      <td>53</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>39df9399f5384334a42905bcf0acdcbf</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>954</td>\n",
       "      <td>8727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>4416745560343f14a74dedcda4ec03b0</td>\n",
       "      <td>60</td>\n",
       "      <td>238</td>\n",
       "      <td>68</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>b51c76411b51751f45527c63c69ead9e</td>\n",
       "      <td>67</td>\n",
       "      <td>352</td>\n",
       "      <td>77</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>237db43817f34988f9d543ca518be4ee</td>\n",
       "      <td>90</td>\n",
       "      <td>360</td>\n",
       "      <td>109</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>618 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Donor ID  donated_projects_test  \\\n",
       "0    7f7fca83ead83a4bb01123429d3114ef                      1   \n",
       "1    787a3bb8aaf99727563c1f62f98610c5                      1   \n",
       "2    774836dd111e337194f91e517df9eb94                      1   \n",
       "3    76d0cdb881c521e1743118634f0c5f28                      1   \n",
       "4    f0ea78ff6ce64e89e929948a60ea09d9                      1   \n",
       "..                                ...                    ...   \n",
       "613  c376c98b0cdb746cf025bb21ee810376                     49   \n",
       "614  39df9399f5384334a42905bcf0acdcbf                     57   \n",
       "615  4416745560343f14a74dedcda4ec03b0                     60   \n",
       "616  b51c76411b51751f45527c63c69ead9e                     67   \n",
       "617  237db43817f34988f9d543ca518be4ee                     90   \n",
       "\n",
       "     donated_projects_train  Donation ID_test  Donation ID_train  \n",
       "0                         8                 1                  9  \n",
       "1                         5                 1                  5  \n",
       "2                        21                 1                 35  \n",
       "3                         8                 1                 14  \n",
       "4                        22                 2                 28  \n",
       "..                      ...               ...                ...  \n",
       "613                     239                53                410  \n",
       "614                      57               954               8727  \n",
       "615                     238                68                538  \n",
       "616                     352                77                702  \n",
       "617                     360               109                898  \n",
       "\n",
       "[618 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_train_comparison_df = pd.merge(right = df_train.groupby('Donor ID').count()[['Donation ID']].reset_index(), left = df_test.groupby('Donor ID').count()[['Donation ID']].reset_index(), on='Donor ID', suffixes=('_test', '_train')).sort_values(by='Donation ID_test').reset_index(drop=True)\n",
    "test_train_comparison_df = pd.merge(right = test_train_comparison_df, left = df_train.groupby('Donor ID'). agg({\"Project ID\": \"nunique\"})[['Project ID']].reset_index().rename(columns={'Project ID': 'donated_projects_train'}), on='Donor ID')\n",
    "test_train_comparison_df = pd.merge(right = test_train_comparison_df, left = df_test.groupby('Donor ID'). agg({\"Project ID\": \"nunique\"})[['Project ID']].reset_index().rename(columns={'Project ID': 'donated_projects_test'}), on='Donor ID')\n",
    "\n",
    "test_train_comparison_df.sort_values(by='donated_projects_test').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Donor ID</th>\n",
       "      <th>donated_projects_test</th>\n",
       "      <th>donated_projects_train</th>\n",
       "      <th>Donation ID_test</th>\n",
       "      <th>Donation ID_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0a497ef14df378d153a16dc7a1abaf8b</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Donor ID  donated_projects_test  \\\n",
       "14  0a497ef14df378d153a16dc7a1abaf8b                      1   \n",
       "\n",
       "    donated_projects_train  Donation ID_test  Donation ID_train  \n",
       "14                       1                 2                 29  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_train_comparison_df[test_train_comparison_df['Donor ID'] == '0a497ef14df378d153a16dc7a1abaf8b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(donor_donated_project_intrain_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donor_id =  774836dd111e337194f91e517df9eb94\n",
      "donor_train_donations_series: 21\n",
      "271\n",
      "5\n",
      "9\n",
      "11\n",
      "709\n",
      "219\n",
      "681\n",
      "40\n",
      "276\n",
      "304\n",
      "305\n",
      "64\n",
      "170\n",
      "238\n",
      "654\n",
      "334\n",
      "389\n",
      "283\n",
      "265\n",
      "267\n",
      "721\n",
      "donor_project_strengths.shape = (21, 1) \n"
     ]
    }
   ],
   "source": [
    "def get_projects_profiles_tfidf(ids, tfidf_matrix):\n",
    "\n",
    "    \"\"\"\n",
    "    input: a series of project ids\n",
    "    output: a matrix of projects tfidfs\n",
    "    \"\"\"\n",
    "    # repeat for all projects\n",
    "    for project_id in np.ravel([ids]):\n",
    "        print(projects_id.index(project_id))\n",
    "\n",
    "    profiles_list = [get_project_profile_tfidf(project_id, tfidf_matrix) for project_id in np.ravel([ids])]\n",
    "    assert len(profiles_list) == len(ids)\n",
    "\n",
    "\n",
    "    # stack them onto each other onto a list\n",
    "    project_profiles = scipy.sparse.vstack(profiles_list)\n",
    "    assert project_profiles.shape[0] == len(ids)\n",
    "\n",
    "    return profiles_list, project_profiles\n",
    "\n",
    "\n",
    "\n",
    "donor_id = '774836dd111e337194f91e517df9eb94'\n",
    "print(\"donor_id = \", donor_id)\n",
    "donor_train_donations_series = df_train_donor_index.loc[donor_id]\n",
    "print(f'donor_train_donations_series: {len(donor_train_donations_series)}')\n",
    "assert len(donor_train_donations_series['Project ID']) == len(donor_train_donations_series['Project ID'].unique())\n",
    "\n",
    "# get the vectors of projects this person has donated to\n",
    "donor_donated_project_intrain_profiles = get_projects_profiles_tfidf(donor_train_donations_series['Project ID'], tfidf_matrix)\n",
    "\n",
    "# get the smoothed donated amount as the weight of each project\n",
    "donor_project_strengths = np.array(donor_train_donations_series['Donation Amount']).reshape(-1, 1)\n",
    "\n",
    "\n",
    "print(f\"donor_project_strengths.shape = {donor_project_strengths.shape} \")\n",
    "#print(\"donor_donated_project_intrain_profiles = \", donor_donated_project_intrain_profiles.shape)\n",
    "#print(\"donor_donated_project_intrain_profiles[0] = \", donor_donated_project_intrain_profiles[0].shape)\n",
    "\n",
    "\n",
    "# multiply the weights and vectors\n",
    "#multiplication = donor_donated_project_intrain_profiles.multiply(donor_project_strengths, )\n",
    "#print('multiplication.shape = ', multiplication.shape)\n",
    "#print('multi: ', multiplication)\n",
    "#print(\"np.sum(multiplication, axis=0) = \", np.sum(multiplication, axis=0))\n",
    "\n",
    "\n",
    "# now we normalize the whole vector \n",
    "#normalized_donor_preference = preprocessing.normalize(multiplication)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_list, project_profiles = donor_donated_project_intrain_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([], shape=(0, 3074), dtype=float64),\n",
       " matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([], shape=(0, 3074), dtype=float64),\n",
       " matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([], shape=(0, 3074), dtype=float64),\n",
       " matrix([], shape=(0, 3074), dtype=float64),\n",
       " matrix([], shape=(0, 3074), dtype=float64),\n",
       " matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([[0., 0., 0., ..., 0., 0., 0.]]),\n",
       " matrix([], shape=(0, 3074), dtype=float64)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.todense() for i in profiles_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[4.44978154],\n",
       "        [3.25510052],\n",
       "        [2.41601787],\n",
       "        [4.63996803],\n",
       "        [3.62637929],\n",
       "        [4.71571741],\n",
       "        [3.60379365],\n",
       "        [2.25056103],\n",
       "        [4.63544108],\n",
       "        [2.97307656],\n",
       "        [3.92293377],\n",
       "        [4.16444729],\n",
       "        [2.92013336],\n",
       "        [3.86502053],\n",
       "        [2.80821062]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_profiles.todense().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_profiles.todense().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================TFIDF=======================#\n",
    "\n",
    "# -------------------projects-------------------#\n",
    "\n",
    "# single project \n",
    "def get_project_profile_tfidf(project_id, tfidf_matrix):\n",
    "\n",
    "    # get the ids\n",
    "    idx = projects_id.index(project_id)\n",
    "    # get the word count vector for that document\n",
    "    project_profile = tfidf_matrix[idx:idx+1]\n",
    "    return project_profile\n",
    "\n",
    "# multiple projects profile\n",
    "def get_projects_profiles_tfidf(ids, tfidf_matrix):\n",
    "\n",
    "    \"\"\"\n",
    "    input: a series of project ids\n",
    "    output: a matrix of projects tfidfs\n",
    "    \"\"\"\n",
    "    # repeat for all projects\n",
    "    for project_id in np.ravel([ids]):\n",
    "        print(projects_id.index(project_id))\n",
    "\n",
    "    profiles_list = [get_project_profile_tfidf(project_id, tfidf_matrix) for project_id in np.ravel([ids])]\n",
    "    assert len(profiles_list) == len(ids)\n",
    "\n",
    "\n",
    "    # stack them onto each other onto a list\n",
    "    project_profiles = scipy.sparse.vstack(profiles_list)\n",
    "    assert project_profiles.shape[0] == len(ids)\n",
    "\n",
    "    return profiles_list, project_profiles\n",
    "\n",
    "\n",
    "\n",
    "# --------------donors------------------#\n",
    "def build_donor_profile_tfidf(donor_id, df_train_donor_index, tfidf_matrix=tfidf_matrix):\n",
    "\n",
    "    # get the id of each person and the projects they\n",
    "    # donated to\n",
    "\n",
    "    print(\"donor_id = \", donor_id)\n",
    "    donor_train_donations_series = df_train_donor_index.loc[donor_id]\n",
    "    print(f'donor_train_donations_series: {len(donor_train_donations_series)}')\n",
    "    assert len(donor_train_donations_series['Project ID']) == len(donor_train_donations_series['Project ID'].unique())\n",
    "\n",
    "    # get the vectors of projects this person has donated to\n",
    "    donor_donated_project_intrain_profiles = get_projects_profiles_tfidf(donor_train_donations_series['Project ID'], tfidf_matrix)\n",
    "    print(f\"donor_donated_project_intrain_profiles.shape = {donor_donated_project_intrain_profiles.shape} \")\n",
    "\n",
    "    # get the smoothed donated amount as the weight of each project\n",
    "    donor_project_strengths = np.array(donor_train_donations_series['Donation Amount']).reshape(-1, 1)\n",
    "    print(f\"donor_project_strengths.shape = {donor_project_strengths.shape} \")\n",
    "\n",
    "    # multiply the weights and vectors\n",
    "    multiplication = np.multiply(donor_donated_project_intrain_profiles, donor_project_strengths)\n",
    "    print('multiplication.shape = ', multiplication.shape)\n",
    "    print('multi: ', multiplication)\n",
    "    print(\"np.sum(multiplication, axis=0) = \", np.sum(multiplication))\n",
    "\n",
    "\n",
    "    # now we normalize the whole vector \n",
    "    normalized_donor_preference = preprocessing.normalize(np.sum(multiplication, axis=0))\n",
    "\n",
    "\n",
    "    return normalized_donor_preference\n",
    "\n",
    "\n",
    "\n",
    "def build_donors_profiles_tfidf(df_test_donor_index, df_train_donor_index, sample_size = 1000):\n",
    "    \n",
    "    # now for all donors we build a profile in a dictionary\n",
    "    donor_profiles = {}\n",
    "    donors_in_test_set = df_test_donor_index.index.unique().tolist()[:sample_size]\n",
    "\n",
    "    for donor_id in tqdm(donors_in_test_set[:sample_size], position=0, leave=True):\n",
    "        donor_profiles[donor_id] = build_donor_profile_tfidf(donor_id, df_train_donor_index)\n",
    "\n",
    "    return donor_profiles\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3074)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_donor_profile_tfidf(donor_id, df_train_donor_index, tfidf_matrix= tfidf_matrix).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =======================TFIDF=======================#\n",
    "\n",
    "# -------------------projects-------------------#\n",
    "\n",
    "# single project \n",
    "def get_project_profile_tfidf(project_id, tfidf_matrix):\n",
    "    \"\"\"\n",
    "    input: a project id\n",
    "    output: the tfidf of that project\n",
    "    \"\"\"\n",
    "    # get the ids\n",
    "    idx = projects_id.index(project_id)\n",
    "\n",
    "    # get the word count vector for that document\n",
    "    project_profile = tfidf_matrix[idx:idx+1]\n",
    "    return project_profile\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# multiple projects profile\n",
    "def get_projects_profiles_tfidf(ids, tfidf_matrix):\n",
    "\n",
    "    \"\"\"\n",
    "    input: a series of project ids\n",
    "    output: a matrix of projects tfidfs\n",
    "    \"\"\"\n",
    "    # repeat for all projects\n",
    "\n",
    "    profiles_list = [get_project_profile_tfidf(project_id, tfidf_matrix) for project_id in np.ravel([ids])]\n",
    "\n",
    "\n",
    "    # stack them onto each other onto a list\n",
    "    project_profiles = scipy.sparse.vstack(profiles_list)\n",
    "\n",
    "    return project_profiles\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------donors------------------#\n",
    "\n",
    "# one donor\n",
    "def build_donor_profile_tfidf(donor_id: str, df_train_donor_index: pd.DataFrame, tfidf_matrix: np.ndarray = tfidf_matrix) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    input: id of one donor, training set\n",
    "    output: a one rowed matrix of donor profile, shape: (1, tfidf_vocab_len) : array([[..., ..., ... ]])\n",
    "    \"\"\"\n",
    "\n",
    "    donor_train_donations_series = df_train_donor_index.loc[donor_id]\n",
    "\n",
    "\n",
    "    # get the vectors of projects this person has donated to\n",
    "    donor_donated_project_intrain_profiles = get_projects_profiles_tfidf(donor_train_donations_series['Project ID'], tfidf_matrix)\n",
    "    \n",
    "\n",
    "    # get the smoothed donated amount as the weight of each project\n",
    "    donor_project_strengths = np.array(donor_train_donations_series['Donation Amount']).reshape(-1, 1)\n",
    "\n",
    "\n",
    "    # multiply the weights and vectors\n",
    "    multiplication = donor_donated_project_intrain_profiles.multiply(donor_project_strengths)\n",
    "\n",
    "\n",
    "    # now we normalize the whole vector \n",
    "    normalized_donor_preference = preprocessing.normalize(np.sum(multiplication, axis=0))\n",
    "\n",
    "\n",
    "    return normalized_donor_preference\n",
    "\n",
    "\n",
    "# multiple donors\n",
    "def build_donors_profiles_tfidf(df_test_donor_index: pd.DataFrame, df_train_donor_index: pd.DataFrame, sample_size: int = 1000):\n",
    "    \n",
    "    \"\"\"\n",
    "    input: donors in test, the trainset, how many donors\n",
    "    output: a dictionary of \"donor_id\": \"tfidf_projects\"\n",
    "\n",
    "    \"\"\"\n",
    "    # now for all donors we build a profile in a dictionary\n",
    "    donor_profiles = {}\n",
    "    donors_in_test_set = df_test_donor_index.index.unique().tolist()[:sample_size]\n",
    "\n",
    "    for donor_id in tqdm(donors_in_test_set[:sample_size], position=0, leave=True):\n",
    "        donor_profiles[donor_id] = build_donor_profile_tfidf(donor_id, df_train_donor_index)\n",
    "\n",
    "    return donor_profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- Content Based------------------ #\n",
    "\n",
    "\n",
    "class ContentBasedRecommender:\n",
    "    MODEL_NAME = 'Content-Based'\n",
    "\n",
    "    def __init__(self, donor_profiles):\n",
    "\n",
    "        self.donor_profiles = donor_profiles\n",
    "        self.tfidf_matrix = tfidf_matrix\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "\n",
    "    def _get_similar_projects_to_donor_profile(self, donor_id:str, top_n=1000):\n",
    "\n",
    "        \"\"\"\n",
    "        gets the donor id and calculates the cosine similarity between donor profile\n",
    "        and projects tfidf\n",
    "        \"\"\"\n",
    "        \n",
    "        cosine_similarities = cosine_similarity(self.donor_profiles[donor_id], self.tfidf_matrix)\n",
    "\n",
    "        # sort them and get the indices\n",
    "        similar_indices = cosine_similarities.argsort()[::-1].flatten()[:top_n]\n",
    "        \n",
    "\n",
    "        # get the id of project and the score of it\n",
    "        similar_projects = sorted([(projects_id[i], cosine_similarities[0, i]) for i in similar_indices], key=lambda x:x[1], reverse=True)\n",
    "        \n",
    "\n",
    "        return similar_projects\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def recommend_projects(self, donor_id: str, projects_to_ignore=[], top_n=10, verbose=False, df_test = df_test):\n",
    "\n",
    "        \"\"\"\n",
    "        gets the donor id \n",
    "        \"\"\"\n",
    "        donated_projects_test = df_test_donor_index.loc[donor_id, 'Project ID']\n",
    "        \n",
    "        similar_projects = self._get_similar_projects_to_donor_profile(donor_id, top_n)\n",
    "\n",
    "\n",
    "        # remove projects from ignore list if it is also in the test set\n",
    "        wanted_in_test = []\n",
    "        for project_id in projects_to_ignore:\n",
    "            if project_id in donated_projects_test:\n",
    "                wanted_in_test.append(project_id)\n",
    "\n",
    "        if wanted_in_test != []: projects_to_ignore = set(projects_to_ignore).difference(wanted_in_test)\n",
    "\n",
    "        similar_projects_filtered = [x for x in similar_projects if x[0] not in projects_to_ignore]\n",
    "\n",
    "        recommendations_df = pd.DataFrame(similar_projects_filtered, columns = ['Project ID', 'recommStrength']).head(top_n)\n",
    "\n",
    "        recommendations_df = recommendations_df.merge(projects_df, how = 'left')[['recommStrength',  'Project ID', 'Project Title', 'Project Need Statement']]\n",
    "\n",
    "        return recommendations_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 618/618 [00:02<00:00, 209.94it/s]\n"
     ]
    }
   ],
   "source": [
    "donor_profiles = build_donors_profiles_tfidf(df_test_donor_index, df_train_donor_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_based_model = ContentBasedRecommender(donor_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTFIDF: \u001b[0m\n",
      "len(validation_projects) =  101\n",
      "len(recommendations_df_fil) =  100\n",
      "len(recommendations_df) =  693\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-5af449a44cdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolored\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TFIDF: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'green'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mglobal_metrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetailed_results_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_evaluator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_based_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\nGlobal metrics:\\n%s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mglobal_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-0babc25ee347>\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdonor_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf_test_donor_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mdonor_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_model_for_donor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdonor_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m500\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%d donors processed'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-0babc25ee347>\u001b[0m in \u001b[0;36mevaluate_model_for_donor\u001b[1;34m(self, model, donor_id)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mrecommended_project_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecommendations_df_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Project ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecommended_project_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrecommendations_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1440\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1442\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1443\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1444\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "print(colored('TFIDF: ', 'green'))\n",
    "global_metrics, detailed_results_df = model_evaluator.evaluate_model(content_based_model)\n",
    "\n",
    "\n",
    "print('\\nGlobal metrics:\\n%s' % global_metrics)\n",
    "detailed_results_df = detailed_results_df[['_donor_id', 'donated_count', \"hits@3_count\", 'hits@5_count', 'hits@10_count', 'recall@3','recall@5','recall@10']]\n",
    "detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_results_df.to_csv('D:\\Papers\\Paper 3 - Recommender Systems\\Results\\detailed_results_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donor_id = '237db43817f34988f9d543ca518be4ee'\n",
    "donor_test = df_test_donor_index.loc[donor_id]\n",
    "donor_test['Project ID'].isin(df_train_donor_index.loc[donor_id, 'Project ID']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_donor_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluator = ModelEvaluator(df_donor_index, projects_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top-N accuracy metrics \n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_PROJECTS = 100\n",
    "\n",
    "\n",
    "class ModelEvaluator:\n",
    "\n",
    "    def __init__(self, df_donor_index, projects_id):\n",
    "\n",
    "        self.df_donor_index = df_donor_index\n",
    "        self.df_test_donor_index = df_test_donor_index\n",
    "        self.df_train_donor_index = df_train_donor_index\n",
    "        self.projects_id = projects_id\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def get_projects_donated(self, donor_id: str) -> set:\n",
    "\n",
    "        \"\"\" \n",
    "        get the project one has donated to in the main df\n",
    "        \"\"\"\n",
    "        try:\n",
    "            donated_projects = self.df_donor_index.loc[donor_id]['Project ID']\n",
    "\n",
    "            return set(donated_projects if type(donated_projects) == pd.Series else [donated_projects])\n",
    "        \n",
    "        except KeyError:\n",
    "            return []\n",
    "\n",
    "\n",
    "    def get_not_donated_projects_sample(self, donor_id: str, sample_size: int, seed=42) -> set:\n",
    "        \n",
    "        \"\"\"\n",
    "        input: donor_id\n",
    "        output: a set of not donated projects in df\n",
    "        \"\"\"\n",
    "        \n",
    "        donated_projects = self.get_projects_donated(donor_id)\n",
    "\n",
    "        not_donated_projects = [x for x in self.projects_id if x not in donated_projects]\n",
    "        not_donated_projects_sample = random.sample(not_donated_projects, sample_size)\n",
    "        \n",
    "        return set(not_donated_projects_sample)\n",
    "\n",
    "\n",
    "\n",
    "    def _verify_hit_top_n(self, project_id: str, recommended_projects: pd.Series, top_n) -> (bool, int):\n",
    "        \"\"\" \n",
    "        input: one project id (a project our donor has donated to), a set of recommended projects\n",
    "        output: the index of that project_id among all the recomms\n",
    "        \"\"\"\n",
    "        try:\n",
    "            index = next(i for i, c in enumerate(recommended_projects) if c == project_id)\n",
    "        except:\n",
    "            index = -1\n",
    "\n",
    "        hit = int(index in range(0, top_n))\n",
    "\n",
    "        return hit, index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate_model_for_donor(self, model, donor_id: str):\n",
    "        \"\"\"\n",
    "        evaluates the recommendations recommended to one donor\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # what donor has donated to in the test set\n",
    "        if type(self.df_test_donor_index.loc[donor_id, 'Project ID']) == pd.Series:\n",
    "            donated_projects_test = set(self.df_test_donor_index.loc[donor_id, 'Project ID'])\n",
    "        else:\n",
    "            donated_projects_test = set([self.df_test_donor_index.loc[donor_id, 'Project ID']])\n",
    "\n",
    "\n",
    "        # how many are they?\n",
    "        donated_projects_count_test = len(donated_projects_test)\n",
    "        train_test_overlap = self.df_train_donor_index.loc[donor_id, 'Project ID'].isin(donated_projects_test).sum()\n",
    "\n",
    "\n",
    "        recommendations_df = model.recommend_projects(donor_id, projects_to_ignore= get_projects_donated(donor_id, df_train_donor_index), top_n = None, df_test=df_test)\n",
    "\n",
    "        \n",
    "        hits_at_3_count = 0\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "\n",
    "         # first get a sample of the ones he\\she has not donated to \n",
    "        not_donated_projects_sample =  self.get_not_donated_projects_sample(donor_id, sample_size = EVAL_RANDOM_SAMPLE_NON_INTERACTED_PROJECTS, seed = 42)\n",
    "            \n",
    "        for project_id in donated_projects_test:\n",
    "\n",
    "\n",
    "            # add a donated project to a list of 100 projects this donor has not interacted with\n",
    "            validation_projects = not_donated_projects_sample.union(set([project_id]))\n",
    "            print('len(validation_projects) = ', len(validation_projects))\n",
    "\n",
    "            \n",
    "            recommendations_df_ =  recommendations_df[recommendations_df['Project ID'].isin(validation_projects)].reset_index(drop=True)\n",
    "            print(\"len(recommendations_df_fil) = \", len(recommendations_df_))\n",
    "            print(\"len(recommendations_df) = \", len(recommendations_df))\n",
    "            \n",
    "\n",
    "            recommended_project_ids = recommendations_df_['Project ID'].values\n",
    "            assert len(recommended_project_ids) == (recommendations_df)\n",
    "\n",
    "\n",
    "            hit_at_3, index_at_3 = self._verify_hit_top_n(project_id, recommended_project_ids, 3)\n",
    "            hits_at_3_count += hit_at_3\n",
    "\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(project_id, recommended_project_ids, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(project_id, recommended_project_ids, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "\n",
    "\n",
    "        # ---------------------------- Recall --------------------------#\n",
    "        recall_at_3 = hits_at_3_count/float(donated_projects_count_test)\n",
    "        recall_at_5 = hits_at_5_count / float(donated_projects_count_test)\n",
    "        recall_at_10 = hits_at_10_count / float(donated_projects_count_test)\n",
    "\n",
    "\n",
    "        donor_metrics = {'donor_id': donor_id,\n",
    "                        'hits@3_count':hits_at_3_count, \n",
    "                         'hits@5_count':hits_at_5_count, \n",
    "                          'hits@10_count':hits_at_10_count, \n",
    "                          'donated_count': donated_projects_count_test,\n",
    "                          'project_overlap_test_train_count': train_test_overlap,\n",
    "                          'recall@3': recall_at_3,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return donor_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        \"\"\"\n",
    "        aggregates the results of evaluate_model_for_donor\n",
    "        \"\"\"\n",
    "        metrics = []\n",
    "\n",
    "        for idx, donor_id in enumerate(list(self.df_test_donor_index.index.unique().values)):\n",
    "            \n",
    "            donor_metrics = self.evaluate_model_for_donor(model, donor_id)\n",
    "            if idx%500 ==0: print('%d donors processed' % idx)\n",
    "\n",
    "            metrics.append(donor_metrics)\n",
    "\n",
    "            detailed_results_df = pd.DataFrame(metrics).sort_values('donated_count',  ascending=False).reset_index(drop=True)\n",
    "            \n",
    "        glob_num_donations = float(detailed_results_df['donated_count'].sum())\n",
    "\n",
    "        global_recall_at_3 = detailed_results_df['hits@3_count'].sum()/ glob_num_donations\n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum()/ glob_num_donations\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum()/ glob_num_donations\n",
    "\n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@3': global_recall_at_3,\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5e48f84046969b800ff52f6d80523bcd1ca3fb1a99f1449e4197bf6c73dc096"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
