{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "\n",
    "#pip install -U sentence-transformers\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import regex as re\n",
    "import zipfile\n",
    "import gc\n",
    "from scipy.stats import boxcox\n",
    "import sys \n",
    "from collections import Counter \n",
    "from tqdm import tqdm \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import warnings, math\n",
    "from termcolor import colored\n",
    "import pickle\n",
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# for eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "\n",
    "# for SVD\n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.sparse import csr_matrix\n",
    "pd.set_option('display.float_format','{:.5f}'.format)\n",
    "\n",
    "# for EMB\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import scipy\n",
    "from sklearn import preprocessing \n",
    "\n",
    "# for TFIDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy\n",
    "from sklearn import preprocessing \n",
    "\n",
    "# for creating a network\n",
    "from sklearn.cluster import KMeans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXT_FEATURES_PATH = 'D:\\Papers\\Paper 3 - Recommender Systems\\Recommender-systems\\Files\\Graph_based\\ext_features_agg.csv'\n",
    "NEW_DF_PATH = 'D:\\Papers\\Paper 3 - Recommender Systems\\Recommender-systems\\Files\\Graph_based\\Oct_28_df.csv'\n",
    "PROJECTS_DF_PATH = \"D:\\Papers\\Paper 3 - Recommender Systems\\Recommender-systems\\Files\\projects.csv\"\n",
    "\n",
    "\n",
    "ext_features = pd.read_csv(EXT_FEATURES_PATH)\n",
    "df = pd.read_csv(NEW_DF_PATH)\n",
    "projects_df = pd.read_csv(PROJECTS_DF_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# donations in Train set:  43,604\n",
      "# donations in Test set:  4,845\n",
      "# Donors in Train set:  790\n",
      "# Donors in Test set:  617\n",
      "# Donors in both Train and Test sets - the ones we choose for evaluation:  \u001b[34m617\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "print('# donations in Train set: ', f\"{len(df_train):,}\")\n",
    "print('# donations in Test set: ',  f\"{len(df_test):,}\")\n",
    "\n",
    "print('# Donors in Train set: ', f\"{len(df_train['Donor ID'].unique()):,}\")\n",
    "print('# Donors in Test set: ',  f\"{len(df_test['Donor ID'].unique()):,}\")\n",
    "\n",
    "\n",
    "print('# Donors in both Train and Test sets - the ones we choose for evaluation: ',\n",
    "      colored(f\"{len(df_train[df_train['Donor ID'].isin(df_test['Donor ID'].values.tolist())]['Donor ID'].unique()):,}\", 'blue'))\n",
    "\n",
    "\n",
    "\n",
    "df_train = df_train[df_train['Donor ID'].isin(df_test['Donor ID'].values.tolist())].reset_index(drop=True)\n",
    "df_test = df_test[df_test['Donor ID'].isin(df_train['Donor ID'].values.tolist())].reset_index(drop=True)\n",
    "\n",
    "# sum of donation in a grouped by donor id dataset\n",
    "df_main_donor_index = df.groupby(by = ['Donor ID', 'Project ID']).sum()[['Donation Amount']].reset_index().set_index('Donor ID')\n",
    "df_train_donor_index = df_train.groupby(by = ['Donor ID', 'Project ID']).sum()[['Donation Amount']].reset_index().set_index('Donor ID')\n",
    "df_test_donor_index = df_test.groupby(by = ['Donor ID', 'Project ID']).sum()[['Donation Amount']].reset_index().set_index('Donor ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects_df = projects_df[projects_df['Project ID'].isin(df['Project ID'])].reset_index(drop=True)\n",
    "\n",
    "project_txt = projects_df.loc[:, 'project_txt']\n",
    "projects_id = projects_df['Project ID'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- embeddings---------------------#\n",
    "model = SentenceTransformer('paraphrase-distilroberta-base-v1') # , device= 'cuda'\n",
    "embeddings = model.encode(project_txt, batch_size=256, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EMBEDDING_PATH, 'wb') as f:\n",
    "    pickle.dump(embeddings, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donor Profile (donor embeddings & donor df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_PATH = 'D:\\Papers\\Paper 3 - Recommender Systems\\Recommender-systems\\Files\\Graph_based\\Oct_28_project_embeddings.pickle'\n",
    "project_embeddings = pd.read_pickle(EMBEDDING_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== Embeddings ==================== #\n",
    "\n",
    "# ----------------------- projects profiles------------------- #\n",
    "def get_project_profile_emb(project_id: str, project_embeddings):\n",
    "\n",
    "    # get the ids\n",
    "    idx = projects_id.index(project_id)\n",
    "    project_profile = project_embeddings[idx:idx+1]\n",
    "    \n",
    "    return project_profile\n",
    "\n",
    "\n",
    "\n",
    "def get_projects_profiles_emb(ids: pd.Series, project_embeddings):\n",
    "\n",
    "\n",
    "    profiles_list = [get_project_profile_emb(project_id, project_embeddings)[0] for project_id in np.ravel([ids])]\n",
    "    project_profiles = np.vstack(profiles_list)\n",
    "\n",
    "    return project_profiles\n",
    "\n",
    "\n",
    "# ----------------------- Donors profiles------------------- #\n",
    "\n",
    "def build_donors_profile_emb(donor_id: str, df_train_donor_index: pd.DataFrame):\n",
    "\n",
    "    # get the id of each person and the projects they\n",
    "    # donated to\n",
    "    donations_donor_df = df_train_donor_index.loc[donor_id]\n",
    "\n",
    "\n",
    "    # get the vectors of projects this person has donated to\n",
    "    donor_donated_project_intrain_profiles = get_projects_profiles_emb(donations_donor_df['Project ID'], project_embeddings)\n",
    "\n",
    "\n",
    "    # get the smoothed donated amount as the weight of each project\n",
    "    donor_project_strengths = np.array(donations_donor_df['Donation Amount']).reshape(-1, 1)\n",
    "\n",
    "\n",
    "    # multiply the weights and tfidf vectors\n",
    "    multiplication = np.multiply(donor_donated_project_intrain_profiles, donor_project_strengths)\n",
    "\n",
    "\n",
    "    # now we normalize the whole vector \n",
    "    normalized_donor_preference = preprocessing.normalize(np.sum(multiplication, axis=0).reshape(1, -1))\n",
    "    \n",
    "\n",
    "\n",
    "    return normalized_donor_preference\n",
    "\n",
    "\n",
    "def build_donors_profiles_emb(df_test_donor_index: pd.DataFrame, df_train_donor_index: pd.DataFrame, sample_size: int = None):\n",
    "    \n",
    "    # now for all donors we build a profile in a dictionary\n",
    "    donor_profiles = {}\n",
    "    donors_in_test_set = df_test_donor_index.index.unique().tolist()[:sample_size]\n",
    "\n",
    "    for donor_id in tqdm(donors_in_test_set[:sample_size], position=0, leave=True):\n",
    "        donor_profiles[donor_id] = build_donors_profile_emb(donor_id, df_train_donor_index)\n",
    "\n",
    "    return donor_profiles\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 617/617 [00:00<00:00, 1377.75it/s]\n"
     ]
    }
   ],
   "source": [
    "donor_profiles_emb = build_donors_profiles_emb(df_test_donor_index, df_train_donor_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(donor_profiles_emb['009d5fc7b87883ffad248db5150bf1fc'][0]) == 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFILE_EMBEDDING_PATH = 'D:\\Papers\\Paper 3 - Recommender Systems\\Recommender-systems\\Files\\Graph_based\\Oct_28_donor_profiles_embeddings.pickle'\n",
    "\n",
    "with open(PROFILE_EMBEDDING_PATH, 'wb') as f:\n",
    "    pickle.dump(donor_profiles_emb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donor df----------------------------------------------------------\n",
    "\n",
    "df_ = pd.merge(df, ext_features[['zip_first_three_digits', 'kmeans_cluster']],\n",
    "             on='zip_first_three_digits', how='inner')\n",
    "\n",
    "user_profile_df = df_.groupby('Donor ID'). agg(\n",
    "    {\n",
    "    'zip_first_three_digits': 'first',\n",
    "     'kmeans_cluster': 'first',\n",
    "     'Donation Amount' : ['sum', 'median'],\n",
    "     'Project Cost': 'median', \n",
    "     'Project Subject Category Tree' : lambda x: \", \".join(x), \n",
    "     'Project ID' : lambda x: \",\".join(x), \n",
    "     'School Metro Type' : lambda x: \",\".join(x),\n",
    "     'Project Grade Level Category' : lambda x:\",\".join(x),\n",
    "     'Donation ID' : 'count'\n",
    "\n",
    "    }\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Donor ID</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Donation Amount</th>\n",
       "      <th>Project Cost</th>\n",
       "      <th>subject_categories</th>\n",
       "      <th>grades</th>\n",
       "      <th>metro_types</th>\n",
       "      <th>donated_projects</th>\n",
       "      <th>donor_zip_first_three_digits</th>\n",
       "      <th>donor_kmeans_cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>median</th>\n",
       "      <th>median</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>009d5fc7b87883ffad248db5150bf1fc</td>\n",
       "      <td>200.95590</td>\n",
       "      <td>0.44020</td>\n",
       "      <td>591.50000</td>\n",
       "      <td>{'Literacy &amp; Language': 189, 'Music &amp; The Arts...</td>\n",
       "      <td>{'Grades 9-12': 17, 'Grades PreK-2': 195, 'Gra...</td>\n",
       "      <td>{'urban': 288, 'suburban': 105}</td>\n",
       "      <td>004a152bbe8952ea5e9d5ef89c179933,004a152bbe895...</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>011ca63acc31287a150a693d92235160</td>\n",
       "      <td>36.03670</td>\n",
       "      <td>0.44020</td>\n",
       "      <td>451.20000</td>\n",
       "      <td>{'Literacy &amp; Language': 24, 'Music &amp; The Arts'...</td>\n",
       "      <td>{'Grades PreK-2': 39, 'Grades 6-8': 22, 'Grade...</td>\n",
       "      <td>{'urban': 40, 'suburban': 35}</td>\n",
       "      <td>010732a68a6a6a7a40b6827355bd2a04,02180b9e9229c...</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Donor ID Donation Amount         Project Cost  \\\n",
       "                                                sum  median       median   \n",
       "0  009d5fc7b87883ffad248db5150bf1fc       200.95590 0.44020    591.50000   \n",
       "1  011ca63acc31287a150a693d92235160        36.03670 0.44020    451.20000   \n",
       "\n",
       "                                  subject_categories  \\\n",
       "                                                       \n",
       "0  {'Literacy & Language': 189, 'Music & The Arts...   \n",
       "1  {'Literacy & Language': 24, 'Music & The Arts'...   \n",
       "\n",
       "                                              grades  \\\n",
       "                                                       \n",
       "0  {'Grades 9-12': 17, 'Grades PreK-2': 195, 'Gra...   \n",
       "1  {'Grades PreK-2': 39, 'Grades 6-8': 22, 'Grade...   \n",
       "\n",
       "                       metro_types  \\\n",
       "                                     \n",
       "0  {'urban': 288, 'suburban': 105}   \n",
       "1    {'urban': 40, 'suburban': 35}   \n",
       "\n",
       "                                    donated_projects  \\\n",
       "                                                       \n",
       "0  004a152bbe8952ea5e9d5ef89c179933,004a152bbe895...   \n",
       "1  010732a68a6a6a7a40b6827355bd2a04,02180b9e9229c...   \n",
       "\n",
       "  donor_zip_first_three_digits donor_kmeans_cluster  \n",
       "                                                     \n",
       "0                          782                    1  \n",
       "1                          295                    0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def organize_features(text):\n",
    "    cleaned_features = [i.strip() for i in text.split(\",\")]\n",
    "    return dict(Counter(cleaned_features))\n",
    "\n",
    "user_profile_df['subject_categories'] = user_profile_df['Project Subject Category Tree']['<lambda>'].apply(organize_features)\n",
    "user_profile_df['grades'] = user_profile_df['Project Grade Level Category']['<lambda>'].apply(organize_features)\n",
    "user_profile_df['metro_types'] = user_profile_df['School Metro Type']['<lambda>'].apply(organize_features)\n",
    "user_profile_df['donated_projects'] = user_profile_df['Project ID']['<lambda>']\n",
    "user_profile_df['donor_zip_first_three_digits'] = user_profile_df['zip_first_three_digits']['first']\n",
    "user_profile_df['donor_kmeans_cluster'] = user_profile_df['kmeans_cluster']['first']\n",
    "\n",
    "\n",
    "user_profile_df = user_profile_df.drop(['Project Grade Level Category',\n",
    "                                  'Project Subject Category Tree', \n",
    "                                  'School Metro Type', 'kmeans_cluster',\n",
    "                                  'Donation ID', 'zip_first_three_digits',\n",
    "                                  'Project ID'], \n",
    "                                 axis=1)\n",
    "\n",
    "user_profile_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROFILE_PATH = 'D:\\Papers\\Paper 3 - Recommender Systems\\Recommender-systems\\Files\\Graph_based\\Oct_28_user_profile.csv'\n",
    "user_profile_df.to_csv(USER_PROFILE_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROFILE_EMBEDDING_PATH = r'D:\\Papers\\Paper 3 - Recommender Systems\\Recommender-systems\\Files\\Graph_based\\Oct_28_donor_profiles_embeddings.pickle'\n",
    "PROJECT_EMBEDDING_PATH = r'D:\\Papers\\Paper 3 - Recommender Systems\\Recommender-systems\\Files\\Graph_based\\Oct_28_project_embeddings.pickle'\n",
    "USER_PROFILE_PATH = r'D:\\Papers\\Paper 3 - Recommender Systems\\Recommender-systems\\Files\\Graph_based\\Oct_28_user_profile.csv'\n",
    "\n",
    "project_embeddings = pd.read_pickle(PROJECT_EMBEDDING_PATH)\n",
    "donor_profiles_emb = pd.read_pickle(PROFILE_EMBEDDING_PATH)\n",
    "user_profile_df = pd.read_csv(USER_PROFILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5e48f84046969b800ff52f6d80523bcd1ca3fb1a99f1449e4197bf6c73dc096"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
